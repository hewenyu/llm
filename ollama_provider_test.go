package llm

import (
	"context"
	"encoding/json"
	"math"
	"net/http"
	"net/http/httptest"
	"net/url"
	"reflect"
	"strings"
	"testing"
	"time"

	"github.com/ollama/ollama/api"
)

func TestOllamaProvider(t *testing.T) {
	// åˆ›å»ºproviderå®ä¾‹
	provider, err := NewOllamaProvider("http://localhost:11434")
	if err != nil {
		t.Fatalf("åˆ›å»ºOllamaProviderå¤±è´¥: %v", err)
	}

	// æµ‹è¯•è·å–åç§°
	t.Run("æµ‹è¯•è·å–æä¾›è€…åç§°", func(t *testing.T) {
		name := provider.Name()
		if name != "ollama" {
			t.Errorf("æœŸæœ›åç§°ä¸º'ollama'ï¼Œå®é™…å¾—åˆ°ï¼š%s", name)
		}
	})

	// æµ‹è¯•åˆ—å‡ºæ¨¡å‹
	t.Run("æµ‹è¯•åˆ—å‡ºå¯ç”¨æ¨¡å‹", func(t *testing.T) {
		ctx := context.Background()
		models, err := provider.ListModels(ctx)
		if err != nil {
			t.Fatalf("åˆ—å‡ºæ¨¡å‹å¤±è´¥: %v", err)
		}
		if len(models) == 0 {
			t.Error("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨æ¨¡å‹")
		}
		// æ‰“å°æ‰¾åˆ°çš„æ¨¡å‹
		t.Logf("æ‰¾åˆ° %d ä¸ªæ¨¡å‹", len(models))
		for _, model := range models {
			t.Logf("æ¨¡å‹åç§°: %s", model.Name)
		}
	})

	// è·å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹åç§°
	ctx := context.Background()
	models, err := provider.ListModels(ctx)
	if err != nil || len(models) == 0 {
		t.Fatal("æ— æ³•è·å–å¯ç”¨æ¨¡å‹")
	}
	modelName := models[1].Name

	// æµ‹è¯•è·å–æ¨¡å‹ä¿¡æ¯
	t.Run("æµ‹è¯•è·å–æ¨¡å‹ä¿¡æ¯", func(t *testing.T) {
		ctx := context.Background()
		modelInfo, err := provider.GetModel(ctx, modelName)
		if err != nil {
			t.Fatalf("è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: %v", err)
		}
		t.Logf("æ¨¡å‹ä¿¡æ¯: %+v", modelInfo)
	})

	// æµ‹è¯•èŠå¤©åŠŸèƒ½
	t.Run("æµ‹è¯•èŠå¤©åŠŸèƒ½", func(t *testing.T) {
		ctx := context.Background()
		request := ChatRequest{
			Messages: []Message{
				{
					Role:    "user",
					Content: "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±",
				},
			},
			Temperature: 0.7,
		}

		response, err := provider.Chat(ctx, modelName, request)
		if err != nil {
			t.Fatalf("èŠå¤©è¯·æ±‚å¤±è´¥: %v", err)
		}

		if response.Message.Content == "" {
			t.Error("èŠå¤©å“åº”å†…å®¹ä¸ºç©º")
		} else {
			t.Logf("èŠå¤©å“åº”: %s", response.Message.Content)
			t.Logf("Tokenä½¿ç”¨æƒ…å†µ: æç¤ºè¯=%d, è¡¥å…¨=%d, æ€»è®¡=%d",
				response.Usage.PromptTokens,
				response.Usage.CompletionTokens,
				response.Usage.TotalTokens)
		}
	})

	// æµ‹è¯•æ–‡æœ¬è¡¥å…¨
	t.Run("æµ‹è¯•æ–‡æœ¬è¡¥å…¨", func(t *testing.T) {
		ctx := context.Background()
		request := CompletionRequest{
			Prompt:      "ä»å‰æœ‰åº§å±±ï¼Œå±±é‡Œæœ‰åº§åº™ï¼Œåº™é‡Œæœ‰ä¸ª",
			Temperature: 0.7,
		}

		response, err := provider.Complete(ctx, modelName, request)
		if err != nil {
			t.Fatalf("æ–‡æœ¬è¡¥å…¨è¯·æ±‚å¤±è´¥: %v", err)
		}

		if response.Text == "" {
			t.Error("è¡¥å…¨å“åº”å†…å®¹ä¸ºç©º")
		} else {
			t.Logf("è¡¥å…¨å“åº”: %s", response.Text)
			t.Logf("Tokenä½¿ç”¨æƒ…å†µ: æç¤ºè¯=%d, è¡¥å…¨=%d, æ€»è®¡=%d",
				response.Usage.PromptTokens,
				response.Usage.CompletionTokens,
				response.Usage.TotalTokens)
		}
	})

	// æµ‹è¯•æ–‡æœ¬åµŒå…¥
	t.Run("æµ‹è¯•æ–‡æœ¬åµŒå…¥", func(t *testing.T) {
		ctx := context.Background()

		testCases := []struct {
			name  string
			input string
		}{
			{
				name:  "çŸ­æ–‡æœ¬",
				input: "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬",
			},
			{
				name:  "é•¿æ–‡æœ¬",
				input: "å‘é‡æ•°æ®åº“æ˜¯ä¸€ç§ä¸“é—¨è®¾è®¡ç”¨äºå­˜å‚¨å’Œé«˜æ•ˆæ£€ç´¢å‘é‡ï¼ˆåµŒå…¥ï¼‰çš„æ•°æ®åº“ç³»ç»Ÿã€‚å®ƒå¯ä»¥ç”¨æ¥å­˜å‚¨æ–‡æœ¬ã€å›¾åƒç­‰æ•°æ®çš„å‘é‡è¡¨ç¤ºï¼Œå¹¶æ”¯æŒç›¸ä¼¼åº¦æœç´¢ã€‚",
			},
			{
				name:  "ç‰¹æ®Šå­—ç¬¦",
				input: "æµ‹è¯•!@#$%^&*()_+ ğŸ˜Š æ¢è¡Œ\nåˆ¶è¡¨ç¬¦\t",
			},
			{
				name:  "å¤šè¯­è¨€",
				input: "ä¸­æ–‡ English æ—¥æœ¬èª í•œêµ­ì–´",
			},
		}

		for _, tc := range testCases {
			t.Run(tc.name, func(t *testing.T) {
				request := EmbeddingRequest{
					Input: tc.input,
				}

				response, err := provider.Embed(ctx, modelName, request)
				if err != nil {
					t.Fatalf("ç”ŸæˆåµŒå…¥å‘é‡å¤±è´¥: %v", err)
				}

				// éªŒè¯å‘é‡ç»´åº¦
				if len(response.Embedding) == 0 {
					t.Error("åµŒå…¥å‘é‡ä¸ºç©º")
				}

				// éªŒè¯å‘é‡å€¼èŒƒå›´
				for i, v := range response.Embedding {
					if math.IsNaN(v) || math.IsInf(v, 0) {
						t.Errorf("å‘é‡ç¬¬%dä¸ªå…ƒç´ æ˜¯æ— æ•ˆå€¼: %v", i, v)
					}
				}

				t.Logf("è¾“å…¥æ–‡æœ¬é•¿åº¦: %d", len(tc.input))
				t.Logf("åµŒå…¥å‘é‡ç»´åº¦: %d", len(response.Embedding))
				t.Logf("Tokenä½¿ç”¨æƒ…å†µ: æç¤ºè¯=%d, æ€»è®¡=%d",
					response.Usage.PromptTokens,
					response.Usage.TotalTokens)

				// éªŒè¯ç›¸åŒè¾“å…¥å¾—åˆ°ç›¸åŒå‘é‡
				response2, err := provider.Embed(ctx, modelName, request)
				if err != nil {
					t.Fatalf("é‡å¤ç”ŸæˆåµŒå…¥å‘é‡å¤±è´¥: %v", err)
				}

				if !reflect.DeepEqual(response.Embedding, response2.Embedding) {
					t.Error("ç›¸åŒè¾“å…¥å¾—åˆ°ä¸åŒçš„åµŒå…¥å‘é‡")
				}
			})
		}
	})
}

// TestOllamaProviderError æµ‹è¯•é”™è¯¯æƒ…å†µ
func TestOllamaProviderError(t *testing.T) {
	// æµ‹è¯•æ— æ•ˆçš„æ¨¡å‹åç§°
	t.Run("æµ‹è¯•æ— æ•ˆçš„æ¨¡å‹åç§°", func(t *testing.T) {
		provider, err := NewOllamaProvider("http://localhost:11434")
		if err != nil {
			t.Fatalf("åˆ›å»ºOllamaProviderå¤±è´¥: %v", err)
		}

		ctx := context.Background()
		_, err = provider.Chat(ctx, "ä¸å­˜åœ¨çš„æ¨¡å‹", ChatRequest{
			Messages: []Message{
				{
					Role:    "user",
					Content: "ä½ å¥½",
				},
			},
		})
		if err == nil {
			t.Error("ä½¿ç”¨æ— æ•ˆæ¨¡å‹åç§°æ—¶æœŸæœ›å¾—åˆ°é”™è¯¯ï¼Œä½†æ²¡æœ‰")
		}
	})
}

func setupMockOllamaServer() (*httptest.Server, *OllamaProvider) {
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		w.Header().Set("Content-Type", "application/json")

		// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²å–æ¶ˆ
		if r.Context().Err() != nil {
			w.WriteHeader(http.StatusGatewayTimeout)
			json.NewEncoder(w).Encode(map[string]string{"error": "context deadline exceeded"})
			return
		}

		// è¯»å–è¯·æ±‚ä½“
		var req struct {
			Input  string `json:"input"`
			Model  string `json:"model"`
			Prompt string `json:"prompt"`
		}
		if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
			w.WriteHeader(http.StatusBadRequest)
			json.NewEncoder(w).Encode(map[string]string{"error": "invalid request body"})
			return
		}

		// æ£€æŸ¥è¾“å…¥
		input := req.Input
		if input == "" {
			input = req.Prompt // æŸäº›APIä½¿ç”¨promptå­—æ®µ
		}
		if input == "" {
			w.WriteHeader(http.StatusBadRequest)
			json.NewEncoder(w).Encode(map[string]string{"error": "empty input is not allowed"})
			return
		}

		// æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
		select {
		case <-r.Context().Done():
			w.WriteHeader(http.StatusGatewayTimeout)
			json.NewEncoder(w).Encode(map[string]string{"error": "context deadline exceeded"})
			return
		case <-time.After(100 * time.Millisecond):
			// ç»§ç»­å¤„ç†
		}

		switch r.URL.Path {
		case "/api/embeddings":
			// æ£€æŸ¥æ¨¡å‹
			if req.Model != "" && req.Model != "mxbai-embed-large" && !strings.Contains(req.Model, "custom") {
				w.WriteHeader(http.StatusBadRequest)
				json.NewEncoder(w).Encode(map[string]string{"error": "unsupported model"})
				return
			}
			json.NewEncoder(w).Encode(map[string]interface{}{
				"embedding": []float64{0.1, 0.2, 0.3},
				"usage": map[string]int{
					"prompt_tokens": len(input),
					"total_tokens":  len(input),
				},
			})
		case "/api/generate":
			json.NewEncoder(w).Encode(map[string]interface{}{
				"response": "test response",
				"usage": map[string]int{
					"prompt_tokens":     len(input),
					"completion_tokens": 10,
					"total_tokens":      len(input) + 10,
				},
			})
		default:
			w.WriteHeader(http.StatusNotFound)
			json.NewEncoder(w).Encode(map[string]string{"error": "unknown endpoint"})
		}
	}))

	serverURL, _ := url.Parse(server.URL)
	provider := &OllamaProvider{
		embedModel: "mxbai-embed-large",
		client:     api.NewClient(serverURL, server.Client()),
	}

	return server, provider
}

func TestOllamaProvider_GetEmbedModel(t *testing.T) {
	server, provider := setupMockOllamaServer()
	defer server.Close()

	got := provider.GetEmbedModel()
	want := "mxbai-embed-large"

	if got != want {
		t.Errorf("GetEmbedModel() = %v, want %v", got, want)
	}
}

func TestOllamaProvider_Embed(t *testing.T) {
	server, provider := setupMockOllamaServer()
	defer server.Close()

	ctx := context.Background()
	request := EmbeddingRequest{
		Input: "test text",
	}

	// ä½¿ç”¨é»˜è®¤çš„åµŒå…¥æ¨¡å‹
	embedModel := provider.GetEmbedModel()
	response, err := provider.Embed(ctx, embedModel, request)

	if err != nil {
		t.Errorf("Embed() error = %v", err)
		return
	}

	// éªŒè¯è¿”å›çš„åµŒå…¥å‘é‡
	expectedEmbedding := []float64{0.1, 0.2, 0.3}
	if len(response.Embedding) != len(expectedEmbedding) {
		t.Errorf("Embed() returned embedding of length %d, want %d", len(response.Embedding), len(expectedEmbedding))
	}
}

func TestOllamaProvider_EmbedWithCustomModel(t *testing.T) {
	server, provider := setupMockOllamaServer()
	defer server.Close()

	ctx := context.Background()
	request := EmbeddingRequest{
		Input: "test text",
		Model: "custom-embed-model", // ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
	}

	// ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹è¿›è¡ŒåµŒå…¥
	_, err := provider.Embed(ctx, request.Model, request)

	// å³ä½¿æ˜¯mockæœåŠ¡å™¨ï¼Œæˆ‘ä»¬ä¹Ÿåº”è¯¥èƒ½å¾—åˆ°æ­£ç¡®çš„å“åº”
	if err != nil {
		t.Errorf("Embed() with custom model error = %v", err)
	}
}

func TestOllamaProvider_EmbedWithInvalidInput(t *testing.T) {
	server, provider := setupMockOllamaServer()
	defer server.Close()

	ctx := context.Background()
	request := EmbeddingRequest{
		Input: "", // ç©ºè¾“å…¥
	}

	embedModel := provider.GetEmbedModel()
	_, err := provider.Embed(ctx, embedModel, request)

	if err == nil {
		t.Error("Expected error with empty input, got nil")
	}
}

func TestOllamaProvider_EmbedWithContext(t *testing.T) {
	server, provider := setupMockOllamaServer()
	defer server.Close()

	// åˆ›å»ºä¸€ä¸ªå¸¦æœ‰è¶…æ—¶çš„ä¸Šä¸‹æ–‡
	ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
	defer cancel()

	request := EmbeddingRequest{
		Input: "test text",
		Metadata: map[string]interface{}{
			"test_key": "test_value",
		},
	}

	embedModel := provider.GetEmbedModel()
	response, err := provider.Embed(ctx, embedModel, request)

	// æ£€æŸ¥ä¸Šä¸‹æ–‡æ˜¯å¦å·²ç»è¶…æ—¶
	if ctx.Err() != nil {
		t.Errorf("Context error: %v", ctx.Err())
		return
	}

	// éªŒè¯å“åº”
	if err != nil {
		t.Errorf("Embed() error = %v", err)
		return
	}

	expectedEmbedding := []float64{0.1, 0.2, 0.3}
	if len(response.Embedding) != len(expectedEmbedding) {
		t.Errorf("Embed() returned embedding of length %d, want %d", len(response.Embedding), len(expectedEmbedding))
	}
}
